= Introduction
This is a basic setup guide for solr 1.3, sunspot 1.3.3.  I am not an expert.  This is what worked for my project.

= Installation

Clone the repo:
  git clone git@github.com:jeremiahishere/sunspot_tutorial.git
  git checkout -t start_tutorial

Install java and sqlite3 if necessary:

  sudo apt-get install sqlite3 libsqlite3-dev2
  sudo apt-get install java6_something

Add to your gemfile:

  gem "sunspot_rails", "~>1.3.3"
  group :development, :test do
    gem "sunspot_solr", "~>1.3.3"
  end

Add to .gitignore:

  /solr/pids
  /solr/data

Run commands:
  
  bundle install
  rails generate sunspot_rails:install
  bundle exec rake sunspot:solr:start sunspot:solr:stop

Starting and stopping the solr server will populate the solr folder and config files.

= Things that are generated

== config/sunspot.yml

Several blocks of yaml that look roughly like this:

  development:
    disabled: false
    solr:
      hostname: localhost
      port: 8982
      log_level: INFO
      auto_commit_after_request: false

Add 'disabled: false' to remind people how to disable indexes in the future.  

Add 'auto_commit_after_request: false' so that the rails server does not automatically commit to the solr index after updating a model.  You will have to manually index or reindex in development after database updates.

An admin for the development solr index should be available at http://localhost/solr.  If using vagrant, the url option may need to be set based on your ip address and hosts file.

  url: 33.33.33.99/solr
  or
  url: dev.project.com/solr

Be very careful with spaces vs tabs in this file.  Vim has the tendency to mix them.  The yaml parser will not be able to read the file if they are mixed.

== solr/conf

Edit solr/conf/solrconfig.xml and uncomment the autoCommit section:

  <autoCommit> 
    <maxDocs>10000</maxDocs>
    <maxTime>1000</maxTime> 
  </autoCommit>

This will set solr to commit after a commit has been alive for 1000 seconds (or maybe microseconds) or if there are 10000 documents to commit.  Commits should not be tied to model updates because you do not want them to delay page loads.  I am not entirely sure how to tweak these numbers to decrease server load.

= Sunspot mixin setup

The sunspot gem has the best documentation for this.  Generally want to use consistent names to help with ordering search results later.

  class LibraryBookTransaction
    searchable do
      text :name
      text :status do
        checked_out? ? "Returned" : "Checked Out"
      end
      time :checkout_at
    end

= Perform a basic search

Save the LibraryBookTransaction changes and start the development solr server

  bundle exec rake sunspot:solr:start

Create several LibraryBookTransaction instances in the console.  Then index the changes on solr

  bundle exec rake sunspot:reindex

Open up the rails console and run the following search:

  search = LibraryBookTransaction.solr_search { fulltext "Returned" }
  search.results

The results should include all of the checked out transactions.

= Sunspot search setup

== View setup

Setup a search form and search results page.

search_form.haml

  = form_tag(search_results_path, :method => :get, :id => 'search') do
    = text_field_tag(:solr, params[:solr], :placeholder => "Search", :id => 'search_box')
    = submit_tag('Search', :id => 'search_button')

search_results.haml

  #solr_search
    = paginate @solr_results.hits
    .results_box
      .header Results
      .body
        - if @solr_results.results.any?
          - @solr_results.results.each do |r| 
            %li= render :partial => "search_result", :object => r, :as => :item
        - else
          #solr_item
            .body
              %h3 No results matched the search terms.

== Controller setup

  def search_results
    searchable_models = [Library, Book, User]

    @solr_results = Sunspot.search searchable_models do
      fulltext params[:solr] do
        boost_fields :name => 2.0
      end
      paginate :page => params[:page], :per_page => Kaminari.config.default_per_page
    end
  end

Individual models can be searched by calling Library.search { args }.  Use Library.solr_search { args| If the search method is already in use by another gem.

= Cucumber setup

Update the config/sunspot.yml file to enable the testing index
 
  test:
    disabled: false
    solr:
      hostname: localhost
      port: 8981
      log_level: WARNING

Update the cucumber task to start and stop the server.  Note that this task also has the selenium/javascript setup and teardown.

  task :cucumber => ['sunspot:solr:start', 'cucumber:setup_selenium', 'cucumber:ok', 'cucumber:shutdown_selenium', 'sunspot:solr:stop']

When calling cucumber with rake, make sure to set the environment
  
  RAILS_ENV=test bundle exec rake cucumber

Add a cucumber step to reindex the solr server

  Given(/^I reindex the solr index$/) do
    Sunspot.searchable.each(&:solr_reindex)
  end

= Word cloud setup

This gem simplifies the sunspot mixin by creating a word cloud of database fields and associations.

Add the gem to Gemfile.
  
  gem "acts_as_word_cloud"

Install

  bundle install
  rails generate acts_as_word_cloud:install

Look at the config file located in config/initializers/acts_as_word_cloud.rb

Add the mixin to a model

  class Library
    acts_as_word_cloud

  class Book
    acts_as_word_cloud :included_methods => [:full_name], :depth => 3

Call the method

  Library.first.word_cloud
  Book.first.word_cloud

Add the method to the searchable block

  class Library
    acts_as_word_cloud

    searchable do
      text :name
      text :word_cloud
    end

= Custom search

Custom search fields can be used to make certain fields match more or fewer search results.  

== Creating a custom search field

Create a field type inside of the types tag. The analyzer tags determine which filters are used for the indexing of records and querying of records.  Each analyzer should have one tokenizer and any number of filters.

  <types>
    ...
    <fieldType class="solr.TextField" name="text_with_phonetic_match" positionIncrementGap="100">
      <analyzer type='index'>
        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
        <filter class="solr.StandardFilterFactory"/>
        <filter class="solr.LowerCaseFilterFactory"/>
        <filter class="solr.PhoneticFilterFactory" encoder="DoubleMetaphone" inject="true"/>
      </analyzer>
      <analyzer type='query'>
        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
        <filter class="solr.StandardFilterFactory"/>
        <filter class="solr.LowerCaseFilterFactory"/>
        <filter class="solr.PhoneticFilterFactory" encoder="DoubleMetaphone" inject="true"/>
      </analyzer>
    </fieldType>
  </types>


Create a dynamic field inside of the fields tag. This adds new searchable types to the sunspot mixin.  It should reference a fieldtype in the type attribute.  Be careful with naming conventions because name ending characters are meaningful.

  <fields>
    ...
    <dynamicField name="*_text_with_phonetic_match" stored="false" type="text_with_partial_match" multiValued="true" indexed="true"/>
  </fields>


Apply the new field to the searchable block on a model

  class Library < ActiveRecord::Base
    searchable do
      text :name, :as => :name_text_with_phonetic_match
      ...

== Tokenizers
==== solr.KeywordTokenizerFactory
- don't tokenize the input at all
==== solr.LetterTokenizerFactory
- tokenize on non alphanumeric characters
==== solr.WhitespaceTokenizerFactory
- tokenize on whitespace
==== solr.StandardTokenizerFactory
- more complex tokenizing that strips extra characters and categorize the search terms
==== solr.PatternTokenizerFactory
- set a regular expression to tokenize the search terms

See more at: http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters#TokenizerFactories

== Filters
==== solr.StandardFilterFactory
- no clue, seems important 
==== solr.LowerCaseFilterFactory
- converts all indexed words and search terms to lower case
==== solr.StopFilterFactory
- applies a stopwords file to the search terms to remove common words
==== solr.SynonymFilterFactory
- similar to the stop filter except that it allows extra matches for synonym pairs
==== solr.PhoneticFilterFactory
- finds similar phonetic spellings of words when indexing
- can work as a misspelled word finder for words with close pronunciation to the search term
==== solr.PorterStemFilterFactory
- normalizes search terms by standardizing pluralization, verb form, and part of speech
- uses the same parser as the phonetic filter but does different things with it
==== solr.EdgeNGramFilterFactory
- match search terms to the beginnings or ends of words in the index
- good for autocomplete searches
==== solr.NGramFilterFactory
- same as the EdgeNgram filter except that it matches partial words on the inside of the indexed words
- requires a tokenizer that is not the standard tokenizer to work.  Recommend whitespace.

See more at: http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters#TokenFilterFactories

== Full substring search
Reasonably general search that matches many misspellings and partial words.  It uses a whitespace tokenizer and an Ngram filter to match partial words as short as two characters.  It will match inner characters of the search term to inner characters of words in the search index.

  <fieldType class="solr.TextField" name="text_with_partial_match" positionIncrementGap="100">
    <analyzer type='index'>
      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
      <filter class="solr.StandardFilterFactory"/>
      <filter class="solr.LowerCaseFilterFactory"/>
      <filter class="solr.PorterStemFilterFactory"/>
      <filter class="solr.PhoneticFilterFactory" encoder="DoubleMetaphone" inject="true"/>
      <filter class="solr.NGramFilterFactory" minGramSize="2" maxGramSize="10"/>
    </analyzer>
    <analyzer type='query'>
      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
      <filter class="solr.StandardFilterFactory"/>
      <filter class="solr.LowerCaseFilterFactory"/>
      <filter class="solr.PorterStemFilterFactory"/>
      <filter class="solr.PhoneticFilterFactory" encoder="DoubleMetaphone" inject="true"/>
    </analyzer>
  </fieldType

== Autocomplete search
Matches search terms to the beginning of words in the search index.  Specifically useful for an ajax autocomplete on a text field.  It responds quickly without stressing the database.

  <analyzer type='index'>
    <tokenizer class="solr.StandardTokenizerFactory"/>
    <filter class="solr.StandardFilterFactory"/>
    <filter class="solr.LowerCaseFilterFactory"/>
    <filter class="solr.EdgeNGramFilterFactory" minGramSize="1" maxGramSize="100" side="front" />
  </analyzer>
  <analyzer type='query'>
    <tokenizer class="solr.StandardTokenizerFactory"/>
    <filter class="solr.StandardFilterFactory"/>
    <filter class="solr.LowerCaseFilterFactory"/>
    <filter class="solr.EdgeNGramFilterFactory" minGramSize="1" maxGramSize="100" side="front" />
  </analyzer>

= Websolr setup

Setting up an index for a production environment with websolr rquires several steps.

First, create an account with websolr and create an index.  I used all default values.

After creating the index, copy solr/conf/schema.xml to the schema in the advanced options tab on the Websolr admin.  You may also need to upload stop words and synonyms.

Update your config/sunspot.yml file with the Websolr configuration.  It should look like this with a hash replacing <long_hash>.

  production:
    disabled: false
    solr:
      hostname: index.websolr.com
      path: /solr/<long_hash>
      port: 80
      log_level: WARNING
      auto_commit_after_request: false

Run on a production server

  RAILS_ENV=production bundle exec rake sunspot:reindex

= Indexing with delayed jobs

I copied this solution and put it into a mixin: http://blog.bigbinary.com/2012/10/11/solr-sunspot-websolr-delayed-job.html

  module DelayedSunspotIndexing
    def self.included(base)
      base.extend ClassMethods
    end 

    module ClassMethods
      def delay_sunspot_indexing

        # delaying solr indexing
        handle_asynchronously :solr_index, queue: 'indexing', priority: 50
        handle_asynchronously :solr_index!, queue: 'indexing', priority: 50

        include DelayedSunspotIndexing::InstanceMethods
        alias_method_chain :remove_from_index, :delayed
      end 
    end 

    module InstanceMethods
      def remove_from_index_with_delayed
        Delayed::Job.enqueue(::RemoveIndexJob.new(record_class: self.class.to_s, attributes: self.attributes), queue: 'indexing', priority: 50) 
      end 
    end 
  end

= Other interesting sunspot features

- Use with to limit search results
- Order the search results
- Use search.each_hit_with_result do |hit, result| to view both hit and result objects.  This will let you access the score of the hit in the display
